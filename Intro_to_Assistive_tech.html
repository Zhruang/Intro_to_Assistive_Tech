<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>Aug the Gallery</title></head>
<body><h1><strong>Augmenting the Gallery - Notes</strong></h1>
<h2>Class Notes</h2>
<h3>2021/02/02</h3>
<p>Lowering the bars of entering subjects and industries</p>
<p>Knowledge in relation to the physical world</p>
<p>Paper -&gt; one of the most two-dimension</p>
<h2>Reading Responses</h2>
<h3>week 02</h3>
<h4>On Licklider’s <em>Man-Computer Symbiosis</em></h4>
<p>In this essay Licklider presents the current (well, his “current” by the time this essay was written) absence of and an ideal vision of a much more smooth, intuitive, “organic” interaction between human and computer. He calls it “symbiosis” much like his example of fig tree and one kind of wasp. Naturally we may come up with the doubt that computer, does not really need human. Certainly, computers require power  in order to operate properly, but the very reason computers are made and then plugged into the power grid is to serve us in one way or another. Computers do not rely on human, at least not in the same way as we rely on computers. But, if we steer away from this “consciousness” philosophical dilemma, Licklider does offer a good discourse on how human and machine can cooperate more efficiently, that is to combine the respective strengths of the two and supplement each other, for a collective goal. (Again, not that a machine needs a goal.) </p>
<p>This ideal situation differs from “mechanically extended man” or “semi-automatic systems” where there are few interactions. This situation requires constant interactions between man and computer that will form loops of information exchange which not only tackle mechanical and repetitive work but also will foster the process of decision-making or interllectual thinking. I am particularly font of Licklider’s idea that such interaction resembles working with “a colleague whose competence supplements your own”. In order to achieve such level of cooperation, man and computer should at least communicate seamlessly. </p>
<p>Again, we may gain better understanding of it by making another analogy. Think of man and computer as two people who speak different languages, and they would work more closely and efficiently through a third language that both of them speak, or body language that to some extent convey meanings universally. And that is the signifance of inventions like the graphical user interface, touch screen, Scratch language, or even any basic high-level programming language to some extent. They, as the “third language”, serve as a midpoint between the world of human and the world of machine where the two could meet with fewer obstacles. </p>
<p>Over the years, this midpoint has shifted more and more towards the world of us, of course, for all these works are set to be done in our favor. If we look at this matter of man-machine communication in a “human-centralism”, such shift enables more people that aren’t so familiar with technology to enhance their living experience more seamlessly with the help of computers and other electronic devices that are being invented daily nowadays without much learning cost.</p>
<h4>On Sutherland’s <em>The Ultimate Display</em></h4>
<p>This is without doubt a piece of writing with limits of its time. Most of the technical difficulties found in the making of computer displays and inventions of new means of interacting with computers through display, that are mentioned in Sutherland’s essay have been conquered over the years. Many concepts imagined in this essay have long infiltrated the mundane life, some other have been proven obsolete and fallen into disuse. </p>
<p>Touchscreen, as a huge part of Sutherland’s research, even surpasses “the typewriter keyboard” which Sutherland himself considered what would be the main tool to communicate with computers, as the primary input device for almost all electronics. Touchscreen becomes the absolute dominating tool to interact with a smartphone; it is implemented on new generations of laptops; it is implemented on treadmills; it even makes its appearance on the center console of the car to replace physical control buttons and knobs. </p>
<p>One advantage of touch screen is that it introduces a more natural way of interacting with the machine. The desire of touching on something after seeing it might one of our instincts that we are born with. And that leads to the idea of overlapped mappings (my made-up word). We are able to immerse more into the experience when more actions from us are performed under consciousness. In the instance of touch screen, that is to say, I know I will be touching and manipulating the thing that I am currently looking at. </p>
<p>Communicating with a computer using a keyboard, especially a few decades ago, requires the person to trigger a series of keys on the keyboard, that is in front of the person, on the desk presumably,  in order to input a series of command lines, that is not in the form of natural language most likely, which will be received by the computer and translated into visual signals on a seperate display further away from the person. A huge amount of ciphering and deciphering, and language learning are involved in such process which will itimidate many people with less knowledge of computer and pull down the fluency of the workflow drastically in many situations. </p>
<p>Touch screen allows the input and output to happen on the very same spot and nearly the same time. As the output display changes its content, for example, after a command was given through a touch, the potential input commands projected onto the display also change accordingly, allowing for a much more flexible and efficient control on the device. And unlike using a keyboard, or a mouse, or a joystick, this process doesn’t need extra matching of the mapping of the input and the one of the output on the user’s end; a event will be triggered exactly at where I touched the screen and a visual (or some other forms of) response will take place potentially in that very spot. </p>
<h4>On Krevelen’s <em>A Survey of Augmented Reality</em></h4>
<p>Krevelen believes that Augmented Reality can “enhance our perception” and help people to see, hear, feel our enviornments more than other can. However, it seems that AR currently hasn’t quite realised such attractive promise. Admittedly, AR does find its place in certain fields like industrial assembly lines and sports broadcasting as mentioned in the essay, but it is yet far from being a handy tool that will meet the demands of ordinary people. </p>
<p>Virtual Reality has made an increasing appearance in the gaming and cinema industries over the years. People have figured out where to position the VR technology in our cultural world. In other words, VR has found its meaning in certain fields and a healthy circulation of production and demand is already established. In the case of AR, however, people are still struggling in many situations to realize the potential of it. “What is the question” for AR? What’s left undone in our everyday life? </p>
<p>To advance in this question, allow me to make the challenge more specific. As there should be an inevitable integration of a real environment and virtual objects (or say information in general), the accessibility of AR is extremely crucial in making it actually handy for the application scenario most likely involves moving around a physical space. I try to use the word “accessibility” instead of “portability” for the reason follows: A smartphone is made extremely portable but we don’t want to pick up it up every time we wants something from it and pause what we are doing at the time. Many commands are be done with our hands off, or even when holding the phone, it doesn’t interrupt with the work at hand. In other words, using AR should ideally introduce as little cost (in every aspect) as possible. It shouldn’t cost a fortune to use; It shouldn’t introduce many extra physical devices; It shouldn’t require a ton of action for us to use; It shouldn’t cost us much extra time. </p>
<p>Integrating AR into smartphones has solved most of the mentioned above, but a critical flaw can be found in many (if not all) of the AR applications: they could be introducing an extra step of action and disrupting, instead of enhancing, our real time experience. To give a specific example, imaging an AR application for museums. As one holds up his/her phone and points the back camera to the artwork in front, all sorts of relevant information, whether in text or in visual, pop up on the phone screen. Maybe, the information is even carefully mapped onto the artwork’s surface, or its wall label. The experience sounds intriguing until one realizes that this largely affects the viewing experience, the experience of standing directly in front of an artwork that exists in the exact place and time. And this as well is why many museum-going enthusiasts belittle those who do nothing but to take photos of every artworks they walk by in a museum. When a physical artwork is transformed into a two-dimensional image on the screen, much of its charm could be lost and never rescued. We then don’t “see more than others see”, rather our vision is potentially shrunk down into a small piece screen. The act of holding up the phone in front of the artwork, disrupt our normal visual experience in the museum. </p>
<p>And part of the reason why audio guide is introduced into museums is that wearing headphones doesn’t conflict with our visual experience and auditory information can flow into our ears while we are seeing the artworks directly with our eyes. That’s why I think Siri is by far the most successful AR application, if we define AR generously. Or, audio guide IS a kind of augmented reality. It seems that when people talk about AR, too much attention is put into the visual while the audio and other senses are easily overlooked. </p>
<p>Nevertheless, the problems found in the attempts of augmenting the visual reality still remain unsolved. How can we archive the level of success in the audio version of AR for instance? An effective antidote is hard to offer at this point. But back to the museum scenario, how can we fit our AR application into moments and bits when people actually will take out their phones so that it can run more transparently?</p>
<h3>week 03</h3>
<h4>On Murray’s <em>Introduction: A Cultural Approach to Interaction Design</em></h4>
<p>“This wealth of possibilities raises our expectations, but the functions are so mysteriously offered or so compromised … we can find ourselves spending hours in frustrating trial and error in order to accomplish simple tasks.” The massive blowout in technological development brings confusions and frustrations to our life on a daily base for new possibilities rarely translate into enhancement of utility in an efficient way. We are a new-born everyday trying to figure out how our fingers and limbs work. Such inability in converting concept into practice is especially profound in the new “digital medium” (as the word preferred by Murray) for a number of reasons.</p>
<p>One, as Murray pointed out, digital medium is yet so new to the eyes of ours. While established subjects and fields have “wheels” of all kinds invented ready to use, we need to invent the “wheels” from the start in new digital mediums. Take Cascading Style Sheet as an example, many features and functions that designers have taken for granted in the traditional typography industry are yet missing in CSS. “new” (to CSS) function modules are being introduced and reworked into CSS standards as Working Draft, Candidate Recommendation and Recommendation frequently. “Punctuation Width Adjustment”, a vital part of East-Asian typography, is yet to find its place in the CSS standard, for instance. It is this lack of pre-fab “building blocks of design” that makes the development of digital mediums difficult to advance at its initial stage.</p>
<p>Two, we are bringing too many “legacy conventions” from the old industry into this new area. Those conventions might be proven effective in the old industry, but adapting those into the new system without much further thinking and improvement would limit the new possibilities only found in digital mediums. Emergence of e-books should lead us to experiment new story-telling narratives and new means of displaying texts rather than to fully embrace the traditional linear full-in-text way of composing a book.</p>
<h3>week 04</h3>
<h4>On DuGay’s <em>Doing Cultural Studies: The Story of the Sony Walkman</em> (Rather a reading note)</h4>
<p>This essay by DuGay can be roughly divided into two parts. The first part discusses the meaning of “culture”, how an object is given certain meaning and how the object is positioned in a myriad of  networks of meanings through the study of Sony Walkman. The second part goes more specifically to analysis of Sony Walkman’s advertising and how certain identification and fantasy are constructed and then linked to the Sony Walkman as an object.</p>
<p>1) What is “culture”? As a word that can be tucked into our daily discourse seamlessly, “culture” is surprisingly hard to define. Wikipedia describes culture as “an umbrella term” which indicates that the word really encompasses a variety of meanings that is almost impossible to cover fully. DuGay in the essay has listed a number of key elements that constitutes culture: “shared, taken-for-granted knowledge”, “the process of human development”, “the way of life of particular groups, peoples, nations or periods” / “whole way of life” and “the production and circulation of meaning”.</p>
<p>2) Language, as the essay (and many other people) would say, is a system of signs to represent things and exchange meanings in a consensual way. English and Chinese, for instance, are two different language systems that represent things and concepts in our world differently. Two symbols from the two systems can refer to the same object. The Chinese word 自行车 (zìxíngchē) and the English word <em>bicycle</em> both refer to that two-wheel, pedal-driven vehicle that we spot on streets everyday. An interesting discovery can be noticed if we analyze the words quite literally. The specific words and characters we use to compose a name for an object to some extent speak about how the users of one language system understand the object. <em>Bicycle</em> may be interpreted as “two circles”, which gives the object its identity by illustrating the fundamental physical composition, or the shape, of the vehicle. 自行车, on the other hand, may be interpreted as “self-running vehicle”, which might reflect people’s impression on such an object when it was first introduced into the country. Another discovery is relevant to the idea of translation. In many cases, learning a second (or third and so on) language relies on first establishing a connection between the foreign language and the language that one already know. So learning the word (symbol) 自行车 might require an English-speaking person to first acknowledge its equivalence to the word (symbol) <em>bicycle</em> before connecting the word straight to the very object. Such process is even more inevitable when describing something abstract and that possesses no physical entity. And it is similar to the process of understanding an object like DuGay says, “[we] map new things in terms of, or by extension or analogy from, things we already know.” In that, “things we already know” and the language we already know serve as a metaphor.</p>
<p>3) Some meanings that we use almost subconsciously and think no further explanation is needed are marked as “literal”. These meanings and ideas almost become the basic building blocks of constructing new meanings for newly-introduced objects, artefacts and ideas. In that, one object might have been embedded in multiple layers of intertwining meanings. As we think our culture as in a “fluid” form, meanings change. Certain “literal” meanings are less used and thus less known. Certain new meanings begin to be widely accepted in a culture. Those basic meaning-building blocks can change through time. People used to use an airplane “iron bird” to better understand this new and almost alien invention, now it has become the most ordinary concept that we in turn can use to describe new things. Say a “drone” is a small plane, for instance.</p>
<p>4) In the middle of the essay DuGay talks about the concept of “soundscape” where he discusses how Sony Walkman can help one escape from the soundscape of the actual world. The topic of escaping from reality through electronic devices has been intensively talked about in recently years with the emergence of smartphones (social media) and more recently, AirPods (let’s consider it as an evolved version of Walkman). The invention of “active noise-cancelling” headphones and earphones has defined the soundscape of many parts of our modern life as “noise”, as the auditory reality that we want to discard. The notion of noise, is rather hard to accurately defined so objectively as even the most beautifully composed and orchestrated music could be considered as noise in the ears of an insomnia patient. When a person wears a pair of noise-cancelling headphones onto the street, he/she might consider “the bustle and hassle” in the city as noise. However, all of a sudden, the situation flipped with the arrival of a global pandemic. People are forced to stay at home, and cities at one point became dead quiet besides of haunting sirens of ambulance. The New York Public Library at such time released an album “Missing Sounds of New York” which consists eight tracks of field-recorded sound of the busy New York before the pandemic. Ironically, that frustrating soundscape of city life we always wanted to escape from becomes the sanctuary away from the depressing indoor life.</p>
</body>
</html>